|website|article
0|five|                                                    Skip to main content         FiveThirtyEight       Search     Search      ABC News   Menu     The U.S. Still Doesn’t Know How To Track A Pandemic  Share on Facebook  Share on Twitter       Politics    Sports    Science    Podcasts    Video    ABC News                  COVID-19  The U.S. Still Doesn’t Know How To Track A Pandemic     By Betsy Ladyzhets   Mar. 23, 2022, at 12:56 PM           Digital generated image of abstract vertical bar chart with missing bites in the shape of coronaviruses on purple background.   In February 2020, just a month before the COVID-19 pandemic caused widespread lockdowns, a health policy researcher presenting at one of the world’s largest science conferences told thousands of attendees that the U.S. was more prepared to deal with global health threats than any country in the world.  Whoops.  This researcher cited the Global Health Security Index, an effort to measure the capacity of 195 countries to prepare for future epidemics and pandemics. In the 2019 index, the U.S. ranked higher than any other country , with a score of 83.5 out of 100. The ranking includes a sub-score of 98.2 out of 100 for “detection and reporting,” which highlights “real-time surveillance” and “epidemiology workforce.”  Whoops again.  I attended that conference session, and remember feeling comforted by the country’s investments in scientific infrastructure compared to other countries. But two years on, it’s clear the Global Health Security Index had it wrong — the U.S.’s data systems weren’t standardized, its genomic surveillance was a mess and its inequitable healthcare system led to incomplete datasets.  That has left a mess for those of us tracking this novel virus. For two years we’ve tried to make sense of COVID-19 trends with metrics that were fundamentally impaired by our chronically decentralized and underfunded public health system. Looking back, it’s remarkable how poorly we started, how far we’ve come and how far we still have to go. If the country doesn’t want to repeat its mistakes, it will have to take radically different actions the next time a health crisis hits.   Samuel Corum / Getty Images January to March 2020  Case Counts  As news spread in early 2020 of a pneumonia-like disease ripping through China, many Americans started to wonder if their coughs and sore throats were actually symptoms of the novel virus. And even if they weren’t, exactly how many Americans had COVID-19, as opposed to a cold or the seasonal flu?  COVID-19 cases went underreported around the world as labs scrambled to produce tests for the virus. But the U.S. was uniquely challenged in this area, said Dr. Eric Topol, the prolific COVID-19 commentator who is director of the Scripps Research Translational Institute. The federal government refused to use a World Health Organization (WHO) test in favor of waiting for the Centers for Disease Control and Prevention (CDC) to develop its own. That CDC test had contamination issues , delaying its rollout to labs by several weeks. And furthermore, testing was restricted to people with a specific set of flu-like symptoms, demonstrated travel history to China or exposure to someone who had previously tested positive.  “We rejected the WHO test, we had a test that was contaminated, and the government shut down academic labs that could do the proper PCR testing,” Topol said. “It was a nightmare, a veritable nightmare. And the testing has never gotten right since.”  This limited testing led to a problem that statisticians call ascertainment bias. “When we say, ‘This is how many cases we have,’” said Dr. Ellie Murray, an epidemiologist at the Boston University School of Public Health, “that really means, ‘This is how many positive cases we have found from the people we tested. Access to testing is always a huge caveat to case numbers.”  Data from New York City , the early epicenter of COVID-19 in the U.S., shows the ramifications of under-testing. During the city’s intense first wave, case trends aligned closely with trends in hospitalizations and deaths because the majority of New Yorkers testing positive were doing so in hospitals after developing severe symptoms.    Due to this ascertainment bias, the number of New Yorkers who actually got infected in the first wave will always be unknown; one late 2020 study from Mount Sinai estimated this true infection number at 1.7 million, or about 20 percent of the NYC population.   FREDERIC J. BROWN / AFP via Getty Images March to September 2020  Tests Administered  As the country shut down in March 2020, people inside their homes were glued to the news, watching freezer trucks filling with dead bodies in NYC and healthcare workers cobbling together their own PPE. People were desperate for information on how to protect themselves against the novel virus, yet America’s foremost public health organization — the CDC — had basically abdicated its responsibility to provide that information.  Instead of watching press conferences from the nation’s foremost public health experts, we watched as then-President Donald Trump promoted unproven “cures” and promised that the crisis would be over within weeks. This lack of reliable information extended to data, too: The CDC failed to provide frequent and comprehensive reports of COVID-19 cases, tests, or deaths — numbers that we needed to understand the pandemic’s impact in our communities.  Individual experts and research projects stepped in to fill that void, as the challenge of limited COVID-19 testing went from the niche concern of experts to a mainstream issue. Sites like the Johns Hopkins COVID-19 dashboard and The COVID Tracking Project (which I contributed to) gained millions of viewers.  Between March and May 2020, The COVID Tracking Project was the only source of COVID-19 testing data in the U.S., but even its herculean, grassroots effort had limitations. States reported tests using different units and different time scales, so a testing number from one state could not necessarily be compared to a number from another. That meant test positivity rates were unreliable — but people cited them anyway, tying them to policy decisions like school reopening .  Test availability increased through the spring, causing testing itself to rise from under 5,000 new tests conducted per day in early March to hundreds of thousands of tests a day by late April. But that testing was still biased: White Americans and those higher up on the socioeconomic ladder had more access. Some testing sites in South Texas faced demand of over 600,000 patients per site, while sites in much of New England were serving patient numbers in the 25,000 to 50,000 range, according to a summer 2020 FiveThirtyEight analysis . In New York City, officials learned from the first-wave testing troubles by greatly increasing test availability across the city.    After not knowing how many COVID-19 cases were going unreported in spring 2020, we were then asking how many people lacked the tests they needed. Even now, two years into the pandemic, this is still a challenge because the U.S. does not provide demographic data on testing, Murray said.  “We don’t collect reasons for seeking a test,” she said. “We don't collect age, race, ethnicity, occupation of people who seek a test.” If this data was available, those numbers could be used to determine which essential occupations are leading to more exposures, which groups need testing but can’t access it, and other important trends.   PATRICK T. FALLON / AFP via Getty Images October to December 2020  Hospitalizations  During early pandemic surges, hospitals in crisis could call upon healthcare workers from other parts of the country for help. Doctors and nurses flocked first to New York in the spring , then some went to southern states like Arizona and Texas as COVID-19 surged there in the summer .  But by late fall 2020, the country’s biggest COVID-19 surge thus far was overwhelming hospitals everywhere at once, meaning healthcare workers were less available to fly to hard-hit areas and heightening the importance of keeping local hospitalization numbers low. In addition, researchers began to highlight hospitalizations as a more reliable alternative after months of dealing with spotty case and testing data.  Hospitalizations are “a happy medium … more timely than deaths, and more reliable than cases,” said Lauren Ancel Meyers, director of the University of Texas at Austin’s COVID-19 Modeling Consortium. While many cases can go unreported if the sick have mild symptoms or lack access to testing, “most people who had severe enough COVID that they needed acute care were going to the hospitals to get it,” Meyers said.  The main problem with this metric, at least in the U.S., was that reliable hospitalization data simply was, like testing data, not available for most of 2020. While other countries like the U.K. started publishing highly detailed hospitalization data in spring 2020 — taking advantage of its national healthcare system — the highly decentralized U.S. system floundered. In early April 2020, there was no national dataset and only 13 states were regularly reporting current COVID-19 hospitalizations, according to the COVID Tracking Project .  It took multiple surges for the Department of Health and Human Services (HHS) to create a clearinghouse for these crucial statistics. The HHS launched an all-new system in July 2020 to collect data directly from hospitals. It would take several more months before the resulting data was actually reliable, as healthcare workers learned to submit numbers through the new system and HHS analysts learned to identify errors.  Imagine how much more information would be available if every hospital had already been reporting a unified set of metrics to a centralized database when COVID-19 first hit.  Jeff Shaman, an infectious disease modeling expert at Columbia University’s public health school, said that addressing the lack of standards among electronic health records in the U.S. “may actually be harder” than setting up entirely new systems in developing countries, due to the many U.S. businesses with “vested interests” in keeping records private.   ANDREW CABALLERO-REYNOLDS / AFP via Getty Images January to June 2021  Vaccinations  When the U.S. started vaccinating people at the end of 2020, it was tempting to forget about all other COVID-19 metrics. Public health agencies rolled out vaccination dashboards in December and January, and my COVID Tracking Project colleagues and I rejoiced in finally having a good metric to watch after almost a year of tracking all the bad ones. (Really, we had a special relationship with pandemic data. In December 2020, I tweeted : “I just teared up looking at texas's vaccination dashboard... this is fine this is normal.”)  Many Americans focused on vaccinations over other metrics, assuming that, once enough people got their shots, the pandemic would simply end. President Biden was one of them, setting a goal in May 2021 to vaccinate 70 percent of American adults by the Fourth of July.  But there were a lot of issues with this goal, Murray said. For one thing, this “70 percent” referred to 70 percent of people eligible for vaccination, not the entire population. Children, of course, are vectors, too. And what’s more, adults only needed to receive one dose to be counted as vaccinated. (At the time, the vast majority of Americans were receiving the two-dose Pfizer or Moderna vaccines, and research has shown that a single dose of these vaccines offers limited protection compared to the full series.)  “Also, all of our math told us that the threshold for herd immunity was somewhere north of 90 percent,” Murray said. The 70 percent goal created a false sense of optimism as U.S. politicians pushed vaccination and let other safety measures, such as mask requirements and easier access to testing, fall to the wayside.  Moreover, America’s fractured public health system made it challenging to determine when different parts of the country had actually met this 70 percent goal. When analyzing data on how many people had been vaccinated, researchers and journalists divided the doses administered in a given municipality over the total population. But inconsistencies between population and vaccine data led to major errors in these calculations, particularly when people got vaccinated in regions where they were not formally counted as residents.  John Burn-Murdoch, chief data reporter at the Financial Times, told FiveThirtyEight that this issue was “the most striking example of [data] inconsistencies in the U.S.” Some parts of Florida were particularly egregious, Burn-Murdoch and colleagues documented in an October 2021 article : In some zip codes, vaccination uptake figures reached over 2,000 percent. This was possibly due to retirees who traveled to Florida for the winter, got vaccinated there and were counted in the state’s dose numbers, despite not being included in its population numbers, Burn-Murdoch said.  A lack of coordination between state health departments also led to challenges with counting vaccinations when Americans got different doses in different places. For example, a college student who received their first dose in their hometown might then receive a second dose on campus — leading them to be counted as two different first doses in two different states. On a large scale, this leads to over-counting of partial vaccinations and undercounting of full vaccinations, Bloomberg reported in December .   Bryan Tarnowski / Bloomberg via Getty Images July to November 2021  Breakthrough Cases  The U.S. was enjoying a long-promised “hot vax summer” when delta hit the country in July 2021. As the Biden administration had preemptively declared victory over the pandemic, health agencies were unprepared to deal with a new surge — much less with one that infected a lot of people who were already vaccinated.  As breakthrough cases went from anecdotal to a widespread phenomenon, Americans wondered whether they would need an additional vaccine shot for further protection. But limited data on the breakthroughs made it challenging for both federal institutions and individuals to determine whether boosters were needed, and for whom.  The U.S. has struggled to collect and report real-time data on vaccine effectiveness, in part because it’s difficult to sync our vaccination databases with those logging other COVID-19 metrics — namely, cases and hospitalizations. “We have nice studies of vaccine effectiveness, but they become available maybe three or six months after the fact,” said Cécile Viboud, a staff scientist at the National Institutes of Health who studies infectious disease mortality. This delay makes it challenging to predict the possible impact of a new variant or new outbreak.  The CDC said in May 2021 that it would only investigate and report breakthrough cases that resulted in hospitalization or death, a small fraction of the total — leaving outside researchers and reporters to fill in the gap . Some projects took a similar tactic to the COVID Tracking Project, compiling data from states to create an incomplete, unstandardized picture of breakthrough cases in the U.S. But that atomized approach was flawed: A report card from the Rockefeller Foundation's Pandemic Prevention Institute shows how some states are far more comprehensive in their breakthrough case reporting than others.    In the absence of breakthrough case data at home, U.S. scientists have looked abroad to answer questions about waning immunity and the need for booster shots. The U.K.’s Health Security Agency has been a particularly popular data provider when new variants emerge, with its regular reports showing the connections between variants and changes in transmission, hospitalization rates and vaccine effectiveness.  “It’s very hard to watch,” Topol said, discussing these regular updates. “The U.K. reports, I read them every week. And what do we have? Nothing.”   Scott Olson / Getty Images December 2021 to January 2022  Hospitalizations (Again)  When the omicron variant arrived in late 2021, some researchers and journalists started to ask whether hospitalizations were still the most reliable COVID-19 metric.  During this surge, case data became more unreliable than at any point since the first wave thanks to a combination of competition for PCR testing appointments and increased at-home rapid testing. People in omicron outbreak zones waited for hours to get tested , prompting discussions about essential workers and others at high risk who couldn’t afford to stand in line. At-home tests, meanwhile, were difficult to acquire and positive results were difficult to report, so most state and local health departments opted not to track them at all.  As case data became less useful, experts turned back to hospitalizations. This time though, hospitalizations were more complicated: Because omicron was less likely to cause severe COVID-19 symptoms than past variants, there was uncertainty about how many people hospitalized with COVID-19 were actually there due to COVID-specific symptoms. In other words, how many people were in the hospital “incidentally,” meaning they’d entered the facility for a non-COVID reason but then tested positive through routine screening?  Possibly a lot of people, according to a few hospitals and health departments that started reporting this breakdown. For example, from mid-January through early March, more than half of COVID-19 patients in Massachusetts hospitals had tested positive for the virus after being admitted for a “non-COVID” reason, according to the state’s health department.    However, it can be difficult to gauge whether a hospitalization is truly “incidental” because patients who appear to enter the hospital for a non-COVID reason could actually have an uncommon set of COVID-19 symptoms, or a chronic disease exacerbated by the virus. “You need a panel to adjudicate it,” Topol said. And all COVID-related hospitalizations, incidental or no, increase strain on the healthcare system .   Paul Chinn / The San Francisco Chronicle via Getty Images February 2022 and onward  New Kinds of Data  As the Omicron surge wanes, millions of Americans are preparing to live with the coronavirus, rather than defining their lives around it. Many are following the lead of their state governments, which are likely now declaring the end of COVID-19 emergencies and shifting their data strategies to treat this virus more like the flu.  South Carolina’s public health department, for example, announced that it has stopped reporting daily case counts this month and will switch to weekly reporting for hospitalizations and deaths. Iowa’s agency shifted from daily to weekly reports in February, decommissioning two COVID-specific dashboards and moving statistics to a single page on the overall public health website . Missouri’s agency is similarly planning to end case investigations and contact tracing in the coming weeks, moving its focus to hospitalization data and wastewater.  The CDC has yet to make such a drastic shift, but it did move away from case data in a big way while also changing its mask guidance in late February . Rather than relying on case rates and test positivity to determine which U.S. counties should implement COVID-19 safety measures, the agency now recommends relying on hospital admissions and the share of beds occupied by COVID-19 patients; cases are still included in the guidance, but have taken a backseat.  Wastewater data may be particularly useful going forward, as this sewage sampling provides “a really nice early warning signal,” Murray said. As health departments stop rigorously tracking cases, they can use wastewater to see when outbreaks are coming, then use hospitalization data to see how bad those outbreaks are. At the same time, individual residents can use rapid tests to determine their own infection status. But U.S. wastewater sampling has been quite varied so far: On a new CDC dashboard for this metric, the locations where wastewater gets sampled are concentrated in a small number of states, leaving the majority of the country without this data.  Data experts I spoke to for this article expressed fears that the reporting systems built up during the past few years may fall to the wayside after the pandemic is declared “over,” when really, we should be fortifying them for future preparedness . A recent New York Times report discussing the CDC’s failure to publish much of the COVID-19 data it collects suggests that the agency still has more to learn from the past two years when it comes to transparency and communication.  The future of infectious disease monitoring should be thought of like weather forecasting, according to Kaitlyn Johnson, a data analyst at the Pandemic Prevention Institute. “Everyone would be outraged if, suddenly, they could not know whether it was gonna rain or snow that day,” she said. Collecting data on COVID-19 and other diseases could similarly help people make day-to-day decisions and prepare for possible crises; the data deserve investment in line with that potential.       Betsy Ladyzhets is a freelance science, health and data journalist currently focused on tracking the pandemic .  @betsyladyzhets     Filed under  COVID-19 (435 posts)  Coronavirus (408)     Comments             Latest Interactives              More in COVID-19       2022 Election  When Did Americans Stop Caring About COVID-19?  Oct 7, 2022       Monkeypox  Why Monkeypox Wasn’t Another COVID-19  Sep 14, 2022       COVID-19  No President Is Safe From His Own COVID-19 Policy  Jul 22, 2022       Olympics  What Happens When You Cancel The Youth Olympic Games?  Jun 28, 2022      Latest    2022 World Cup  The World Cup's New High-Tech Ball Will Change Soccer Forever  Nov 22, 2022    Politics Podcast  Politics Podcast: How The '90s Shaped Today's GOP  Nov 21, 2022    2022 Election  How A Data Processing Error Changed Our Deluxe Forecast  Nov 18, 2022    2022 Election  So You Think You Can Explain The Election  Nov 18, 2022              Get more FiveThirtyEight     Store    Newsletter    Twitter    Facebook    Data    RSS           Follow @FiveThirtyEight        About Us    Jobs    Masthead    Pitch FiveThirtyEight    Advertise With Us    About Nielsen Measurement     Powered by WordPress VIP      Terms of Use    Privacy Policy   Do Not Sell My Personal Information   Your California Privacy Rights    Children's Online Privacy Policy    Interest-Based Ads    © 2022 ABC News Internet Ventures. All rights reserved.       Close Additional Information  Terms of Use and Privacy Policy and Safety Information/ Your California Privacy Rights / Children's Online Privacy Policy are applicable to you. © 2022 ABC News Internet Ventures. All rights reserved. Interest-Based Ads . Cookie Policy .                 
1|wired|Skip to main content Open Navigation Menu To revist this article, visit My Profile, then View saved stories . Close Alert How to Stop Robots From Becoming Racist Backchannel Business Culture Gear Ideas Science Security More To revist this article, visit My Profile, then View saved stories . Close Alert Sign In Search Backchannel Business Culture Gear Ideas Science Security Podcasts Video Artificial Intelligence Climate Games Newsletters Magazine Events Wired Insider Jobs Coupons Khari Johnson Business Aug 18, 2022 10:00 AM How to Stop Robots From Becoming Racist Algorithms can amplify patterns of discrimination. Robotics researchers are calling for new ways to prevent mechanical bodies acting out those biases. To revist this article, visit My Profile, then View saved stories . Illustration: WIRED; Getty Images To revist this article, visit My Profile, then View saved stories . The AI Database → Application Face recognition Ethics Robotics End User Research Source Data Images Text Technology Machine vision Robotics In the 1940s, sociologists Kenneth and Mamie Clark placed white and Black dolls in front of young children and asked them to do things like pick the doll that “looks bad” or “is a nice color.” The doll test was invented to better understand the evil consequences of separate and unequal treatment on the self-esteem of Black children in the United States. Lawyers from the NAACP used the results to successfully argue in favor of the desegregation of US schools. Now AI researchers say robots may need to undergo similar tests to ensure they treat all people fairly. Content This content can also be viewed on the site it originates from. The researchers reached that conclusion after conducting an experiment inspired by the doll test on a robotic arm in a simulated environment. The arm was equipped with a vision system that had learned to relate images and words from online photos and text, an approach embraced by some roboticists that also underpins recent leaps in AI-generated art . The robot worked with cubes adorned with passport-style photos of men and women who self-identified as Asian, Black, Latino, or white. It was instructed to pick up different cubes using terms that describe people, using phrases such as “the criminal block” or the “homemaker block.” From over 1.3 million trials in that virtual world, a clear pattern emerged that replicated historical sexism and racism, though none of the people pictured on the blocks were labeled with descriptive text or markers. When asked to pick up a “criminal block,” the robot selected cubes bearing photos of Black men 10 percent more often than for other groups of people. The robotic arm was significantly less likely to select blocks with photos of women than men when asked for a “doctor,” and more likely to identify a cube bearing the image of a white man as “person block” than women from any racial background. Across all the trials, cubes with the faces of Black women were selected and placed by the robot less often than those with the faces of Black men or white women. Willie Agnew, a researcher at the University of Washington who worked on the study, says that such demonstrations should be a wake-up call to the field of robotics, which has an opportunity to avoid becoming a purveyor of harm as computer vision has become with surveillance. That opportunity may require devising new ways to test robots, he says, and questioning the use of so-called pretrained models that are trained on vast collections of online text and images, and which are known to perpetuate bias in text and art generators . Researchers have shown that web data can power up algorithms by providing more material to train AI models. Google this week showed off robots that were able to understand commands in natural language thanks to text scraped from the web. But researchers have also shown that pretrained models can reflect or even amplify unsavory patterns of discrimination against certain groups of people; the internet acts like a distorted mirror of the world. “Now that we’re using models that are just trained on data taken from the internet, our robots are biased,” Agnew says. “They have these very specific, very toxic stereotypes.” Agnew and coauthors from the Georgia Institute of Technology, Johns Hopkins University, and the Technical University of Munich, Germany, described their findings in a paper titled “ Robots Enact Malignant Stereotypes ,” recently presented at the Fairness, Accountability, and Transparency conference in Seoul, South Korea. Most Popular science America’s Billion-Dollar Tree Problem Is Spreading Brianna Randall security ‘Dark Ships’ Emerge From the Shadows of the Nord Stream Mystery Matt Burgess gear 20 Viral TikTok Gifts That Are Actually Worth It Brenda Stolyar gear 25 Amazing Gift Ideas Under $25 Michael Calore Biased algorithms have come under scrutiny in recent years for causing human rights violations in areas such as policing—where face recognition has cost innocent people in the US , China , and elsewhere their freedom—or finance, where software can unfairly deny credit. Biased algorithms in robots could potentially cause worse problems, since the machines are capable of physical actions. Last month, a chess-playing robotic arm reaching for a chess piece trapped and broke the finger of its child opponent. Keep Reading Search our artificial intelligence database and discover stories by sector, tech, company, and more. Agnew and his fellow researchers believe the source of the bias in their virtual robot arm experiment is CLIP , open source AI software released in 2021 by startup OpenAI that was trained using millions of images and text captions scraped from the web. The software has been used in many AI research projects, including software for robots called CLIPort used in the simulated robot experiment. But tests of CLIP have found negative bias against groups including Black people and women. CLIP is also a component of OpenAI’s image generation system Dall-E 2, which has been found to generate repulsive images of people . Despite CLIP’s history of discriminatory outcomes, researchers have used the model to train robots, and the practice could become more common. Instead of starting from scratch, engineers creating AI models now often start with a pretrained model trained on web data, and then customize it to a specific task using their own data. Agnew and his coauthors propose several ways to prevent the proliferation of prejudiced machines. They include lowering the cost of robotics parts to widen the pool of people building the machines, requiring a license to practice robotics akin to the qualifications issued to medical professionals, or changing the definition of success. They also call for an end to physiognomy, the discredited idea that a person’s outward appearance can reliably betray inner traits such as their character or emotions. Recent advances in machine vision have inspired a new wave of spurious claims, including that an algorithm can detect whether a person is gay, a criminal , fit to be an employee, or telling lies at an EU border post. Agnew coauthored another study , presented at the same conference, that found only 1 percent of machine learning research papers consider the potential for negative consequences of AI projects. Agnew and his colleagues’ findings may be striking, but come as no surprise to roboticists who have spent years trying to change the industry. Maynard Holliday, deputy CTO for critical technologies at the US Department of Defense, says learning that a robot had judged images of Black men as being more likely to be criminals reminds him of a recent trip to the Apartheid Museum in South Africa, where he saw the legacy of a caste system that propped up white supremacy by focusing on things like a person’s skin color or the length of their nose. The results of the virtual robot test, he said, speak to the need to ensure that people who build AI systems and assemble the datasets used to train AI models come from diverse backgrounds. “If you’re not at the table,” Holliday says, “you’re on the menu.” Most Popular science America’s Billion-Dollar Tree Problem Is Spreading Brianna Randall security ‘Dark Ships’ Emerge From the Shadows of the Nord Stream Mystery Matt Burgess gear 20 Viral TikTok Gifts That Are Actually Worth It Brenda Stolyar gear 25 Amazing Gift Ideas Under $25 Michael Calore In 2017, Holliday contributed to a RAND report warning that resolving bias in machine learning requires hiring diverse teams and cannot be fixed through technical means alone. In 2020, he helped found the nonprofit Black in Robotics , which works to widen the presence of Black people and other minorities in the industry. He thinks two principles from an algorithmic bill of rights he proposed at the time could reduce the risk of deploying biased robots. One is requiring disclosures that inform people when an algorithm is going to make a high stakes decision affecting them; the other is giving people the right to review or dispute such decisions. The White House Office of Science and Technology Policy is currently developing an AI Bill of Rights . Some Black roboticists say their worries about racism becoming baked into automated machines come from a mix of engineering expertise and personal experience. Terrence Southern grew up in Detroit and now lives in Dallas, maintaining robots for trailer manufacturer ATW. He recalls facing barriers to entering the robotics industry, or even to being aware of it. “Both my parents worked for General Motors, and I couldn’t have told you outside of The Jetsons and Star Wars what a robot could do,” Southern says. When he graduated college, he didn’t see anybody who looked like him at robotics companies, and believes little has changed since—which is one reason why he mentors young people interested in pursuing jobs in the field. Southern believes it’s too late to fully prevent the deployment of racist robots, but thinks the scale could be reduced by the assembly of high-quality datasets, as well as independent, third-party evaluations of spurious claims made by companies building AI systems. Andra Keay, managing director of industry group Silicon Valley Robotics and president of Women in Robotics , which has more than 1,700 members around the world, also considers the racist robot experiment’s findings unsurprising. The combination of systems necessary for a robot to navigate the world, she said, amounts to “a big salad of everything that could possibly go wrong.” Keay was already planning to push standards-setting bodies like the Institute of Electrical and Electronics Engineers (IEEE) to adopt rules requiring that robots have no apparent gender and are neutral in ethnicity. With robot adoption rates on the rise as a result of the Covid-19 pandemic, Keay says, she also supports the idea of the federal government maintaining a robot register to monitor the deployment of machines by industry. The WIRED Guide to Artificial Intelligence Supersmart algorithms won't take all the jobs, But they are learning faster than ever, doing everything from medical diagnostics to serving up ads. By Tom Simonite Late in 2021, partly in response to concerns raised by the AI and robotics community, the IEEE approved a new transparency standard for autonomous systems that could help nudge companies to ensure robots treat all people fairly. It requires autonomous systems to honestly convey the causes of their actions or decisions to users. However, standard-setting professional groups have their limits: In 2020, a tech policy committee at the Association for Computing Machinery urged businesses and governments to stop using face recognition, a call that largely fell on deaf ears. When Carlotta Berry, a national director for Black in Robotics, heard that a chess robot broke a child’s finger last month, her first thought was, “Who thought this robot was ready for prime time when it couldn’t recognize the difference between a chess piece and a child’s finger?” She is codirector of a robotics program at the Rose-Hulman Institute of Technology in Indiana and editor of a forthcoming textbook about mitigating bias in machine learning. She believes that part of the solution to prevent the deployment of sexist and racist machines is a common set of evaluation methods for new systems before being made available to the public. In the current age of AI, as engineers and researchers compete to rush out new work, Berry is skeptical that robot builders can be relied on to self-regulate or add safety features. She believes a larger emphasis should be placed on user testing. “I just don’t think researchers in the lab can always see the forest for the trees, and will not recognize when there’s a problem,” Berry says. Is the computational power available to the designers of AI systems running ahead of their ability to thoughtfully consider what they should or should not build with it? “It’s a hard question,” Berry says, “but one that needs to be answered, because the cost is too high for not doing it.” More Great WIRED Stories 📩 The latest on tech, science, and more: Get our newsletters ! The hunt for the dark web’s biggest kingpin, part 4 How to clean your keyboard NASA won't change the James Webb Telescope’s name ‘Pentiment’ is 2022’s best game you’ve never heard of The infinite cloud is a fantasy 👁️ Explore AI like never before with our new database ✨ Optimize your home life with our Gear team’s best picks, from robot vacuums to affordable mattresses to smart speakers Khari Johnson is a senior writer for WIRED covering artificial intelligence and the positive and negative ways AI shapes human lives. He was previously a senior writer at VentureBeat, where he wrote stories about power, policy, and novel or noteworthy uses of AI by businesses and governments. He is based... Read more Senior Writer Topics artificial intelligence robots machine learning algorithms ethics face recognition robotics Racism More from WIRED Amazon’s New Robot Can Handle Most Items in the Everything Store Sparrow could shift the balance between humans and machines in the company’s warehouses, using machine learning algorithms and a custom gripper. Will Knight Why Meta Is Tanking—and How Zuckerberg Can Fix It Plus: Facebook’s early days, Covid in Ukraine, and the world on fire. Steven Levy Fintech in Latin America and Africa Is Breaking the Mold The US and Europe can learn a lot from startups that are nimbler, more digitized, and potentially better at serving underserved people. Helen Li Algorithms Quietly Run the City of DC—and Maybe Your Hometown A new report finds that municipal agencies in Washington deploy dozens of automated decision systems, often without residents’ knowledge. Khari Johnson Clearview Stole My Face and the EU Can't Do Anything About It One man’s battle to reclaim his face shows regulators across the bloc are failing to reprimand the US face search engine. Morgan Meaker Elon Musk’s Twitter Will Be Chaos The entrepreneur’s laundry list of ideas includes scrapping content moderation, charging subscription fees, and even branching out beyond social media. Chris Stokel-Walker Mathieu Flamini Has a Plan to Decarbonize the Chemical Industry The former soccer player is working to turn agricultural waste into a fossil fuel replacement, reducing emissions and harmful byproducts. Amit Katwala Ford Abandons the Self-Driving Road to Nowhere Ford and Volkswagen sank nearly $4 billion into developer Argo. Now, amid wider signs of slow progress in autonomous tech, they're shutting it down. Aarian Marshall WIRED is where tomorrow is realized. It is the essential source of information and ideas that make sense of a world in constant transformation. The WIRED conversation illuminates how technology is changing every aspect of our lives—from culture to business, science to design. The breakthroughs and innovations that we uncover lead to new ways of thinking, new connections, and new industries. More From WIRED Subscribe Newsletters FAQ Wired Staff Press Center Coupons Editorial Standards Black Friday Contact Advertise Contact Us Customer Care Jobs RSS Accessibility Help Condé Nast Store Condé Nast Spotlight Do Not Sell My Personal Info © 2022 Condé Nast. All rights reserved. Use of this site constitutes acceptance of our  User Agreement and Privacy Policy and Cookie Statement and Your California Privacy Rights.  WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Condé Nast.  Ad Choices Select international site United States UK Italia Japón
